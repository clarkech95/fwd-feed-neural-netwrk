{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Name: Christian Clarke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import any required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 – Data Acquisition\n",
    "Load the training data 'house_prices_train.csv' into a dataframe. Explore the data to get a better understanding of its structure and any data preparation steps that you need to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1460 rows and 81 columns.\n"
     ]
    }
   ],
   "source": [
    "#Load the data and view the dimensions\n",
    "#TODO: provide the url for the training data\n",
    "url      = 'https://raw.githubusercontent.com/davashu/module-08-feed-forward-neural-networks-clarkech95/master/house_prices_train.csv?token=APVD6MIBYXPKR2P64IAXFPC7CNWEA' \n",
    "data     = pd.read_csv(url)\n",
    "data_dim = data.shape\n",
    "\n",
    "print ('There are {} rows and {} columns.'.format(data_dim[0], data_dim[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view samples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view a few observations\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use your intuition!\n",
    "At first glance is there any field that, without a doubt, will not contribute to the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: remove/exclude the unnecessary field(s) that will not contribute towards the prediction\n",
    "data.drop('Id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 – Data Exploration\n",
    "- Gather summary/descriptive statistics and inspect **all the fields**. This can help you to identify outliers and detect any inconsistencies\n",
    "- View the frequency of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     56.897260    70.049958   10516.828082     6.099315     5.575342   \n",
       "std      42.300571    24.284752    9981.264932     1.382997     1.112799   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n",
       "50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n",
       "75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n",
       "count  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000  ...   \n",
       "mean   1971.267808   1984.865753   103.685262   443.639726    46.549315  ...   \n",
       "std      30.202904     20.645407   181.066207   456.098091   161.319273  ...   \n",
       "min    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%    1954.000000   1967.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%    1973.000000   1994.000000     0.000000   383.500000     0.000000  ...   \n",
       "75%    2000.000000   2004.000000   166.000000   712.250000     0.000000  ...   \n",
       "max    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: gather descriptive statistics to view the range of values in each field. \n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LotFrontage', 259, 110),\n",
       " ('Alley', 1369, 2),\n",
       " ('MasVnrType', 8, 4),\n",
       " ('MasVnrArea', 8, 327),\n",
       " ('BsmtQual', 37, 4),\n",
       " ('BsmtCond', 37, 4),\n",
       " ('BsmtExposure', 38, 4),\n",
       " ('BsmtFinType1', 37, 6),\n",
       " ('BsmtFinType2', 38, 6),\n",
       " ('Electrical', 1, 5),\n",
       " ('FireplaceQu', 690, 5),\n",
       " ('GarageType', 81, 6),\n",
       " ('GarageYrBlt', 81, 97),\n",
       " ('GarageFinish', 81, 3),\n",
       " ('GarageQual', 81, 5),\n",
       " ('GarageCond', 81, 5),\n",
       " ('PoolQC', 1453, 3),\n",
       " ('Fence', 1179, 4),\n",
       " ('MiscFeature', 1406, 4)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: show the frequency of missing values\n",
    "[ (i,data[i].isna().sum(), len(data[i].value_counts())) for i in data.columns if data[i].isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State your observations about the summary statistics and missing values **(in this cell)**:\n",
    "- There are quite a few columns with a significant amount of missing values, those columns should probably be removed entirely since imputing them will be too difficult and can skew the data.\n",
    "- There are a few columns where it seems almost all of the data falls into a singular bucket, those columns should also potentially be removed since there is little variation and thus may have a lower ability to tell us anything about the data.\n",
    "- The vast majority of columns aren't missing any data which is excellent!\n",
    "- There are a large amount of categorical columns which means we'll have to do a bit of encoding, even a few of the continous columns are actually categorical and have just been encoded already.\n",
    "- There is a decent amount of variety in the sales prices of the properties in the dataset, also since the mean is greater than the median we have a few very highly priced homes that don't fit the norm.\n",
    "\n",
    "Note: recall that not all missing values need to be deleted, some of them can be imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The continuous and categorical independent variables\n",
    "List the continuous and categorical data and state any discrepancy between the number of expected records in the dataset and the `count` that is reported above. \n",
    "\n",
    "For the fields that are discussed, view `data_description.txt` which explains the range of values for each field. What does this tell you about these 'missing' values. How do you recommend addressing them? **(You do not need to demonstrate your recommendations)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MSSubClass', dtype('int64')),\n",
       " ('MSZoning', dtype('O')),\n",
       " ('LotFrontage', dtype('float64')),\n",
       " ('LotArea', dtype('int64')),\n",
       " ('Street', dtype('O')),\n",
       " ('Alley', dtype('O')),\n",
       " ('LotShape', dtype('O')),\n",
       " ('LandContour', dtype('O')),\n",
       " ('Utilities', dtype('O')),\n",
       " ('LotConfig', dtype('O')),\n",
       " ('LandSlope', dtype('O')),\n",
       " ('Neighborhood', dtype('O')),\n",
       " ('Condition1', dtype('O')),\n",
       " ('Condition2', dtype('O')),\n",
       " ('BldgType', dtype('O')),\n",
       " ('HouseStyle', dtype('O')),\n",
       " ('OverallQual', dtype('int64')),\n",
       " ('OverallCond', dtype('int64')),\n",
       " ('YearBuilt', dtype('int64')),\n",
       " ('YearRemodAdd', dtype('int64')),\n",
       " ('RoofStyle', dtype('O')),\n",
       " ('RoofMatl', dtype('O')),\n",
       " ('Exterior1st', dtype('O')),\n",
       " ('Exterior2nd', dtype('O')),\n",
       " ('MasVnrType', dtype('O')),\n",
       " ('MasVnrArea', dtype('float64')),\n",
       " ('ExterQual', dtype('O')),\n",
       " ('ExterCond', dtype('O')),\n",
       " ('Foundation', dtype('O')),\n",
       " ('BsmtQual', dtype('O')),\n",
       " ('BsmtCond', dtype('O')),\n",
       " ('BsmtExposure', dtype('O')),\n",
       " ('BsmtFinType1', dtype('O')),\n",
       " ('BsmtFinSF1', dtype('int64')),\n",
       " ('BsmtFinType2', dtype('O')),\n",
       " ('BsmtFinSF2', dtype('int64')),\n",
       " ('BsmtUnfSF', dtype('int64')),\n",
       " ('TotalBsmtSF', dtype('int64')),\n",
       " ('Heating', dtype('O')),\n",
       " ('HeatingQC', dtype('O')),\n",
       " ('CentralAir', dtype('O')),\n",
       " ('Electrical', dtype('O')),\n",
       " ('1stFlrSF', dtype('int64')),\n",
       " ('2ndFlrSF', dtype('int64')),\n",
       " ('LowQualFinSF', dtype('int64')),\n",
       " ('GrLivArea', dtype('int64')),\n",
       " ('BsmtFullBath', dtype('int64')),\n",
       " ('BsmtHalfBath', dtype('int64')),\n",
       " ('FullBath', dtype('int64')),\n",
       " ('HalfBath', dtype('int64')),\n",
       " ('BedroomAbvGr', dtype('int64')),\n",
       " ('KitchenAbvGr', dtype('int64')),\n",
       " ('KitchenQual', dtype('O')),\n",
       " ('TotRmsAbvGrd', dtype('int64')),\n",
       " ('Functional', dtype('O')),\n",
       " ('Fireplaces', dtype('int64')),\n",
       " ('FireplaceQu', dtype('O')),\n",
       " ('GarageType', dtype('O')),\n",
       " ('GarageYrBlt', dtype('float64')),\n",
       " ('GarageFinish', dtype('O')),\n",
       " ('GarageCars', dtype('int64')),\n",
       " ('GarageArea', dtype('int64')),\n",
       " ('GarageQual', dtype('O')),\n",
       " ('GarageCond', dtype('O')),\n",
       " ('PavedDrive', dtype('O')),\n",
       " ('WoodDeckSF', dtype('int64')),\n",
       " ('OpenPorchSF', dtype('int64')),\n",
       " ('EnclosedPorch', dtype('int64')),\n",
       " ('3SsnPorch', dtype('int64')),\n",
       " ('ScreenPorch', dtype('int64')),\n",
       " ('PoolArea', dtype('int64')),\n",
       " ('PoolQC', dtype('O')),\n",
       " ('Fence', dtype('O')),\n",
       " ('MiscFeature', dtype('O')),\n",
       " ('MiscVal', dtype('int64')),\n",
       " ('MoSold', dtype('int64')),\n",
       " ('YrSold', dtype('int64')),\n",
       " ('SaleType', dtype('O')),\n",
       " ('SaleCondition', dtype('O')),\n",
       " ('SalePrice', dtype('int64'))]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,data[i].dtype) for i in data.columns]\n",
    "\n",
    "# The discrepancies seem to be based on missing values not being accounted for\n",
    "# They actually aren't missing values at all but indicative of a true state in the data\n",
    "# They just need to be changed into an appropriate value for the field they are in\n",
    "# They don't need to be deleted\n",
    "# Columns where nearly all of the values are 'missing' should proably still be removed though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dependent variable\n",
    "Are there any discrepancies with the dependent variable? Plot a histogram showing its distribution. Is the distribution skewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce031086d8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Plot the histogram\n",
    "data['SalePrice'].hist()\n",
    "\n",
    "# No apparent discrepancies\n",
    "# The distribution is skewed to the right though as expected from the describe output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Pipeline\n",
    "Based on your recommendations above, lets build a pipeline that does the following:\n",
    "- prepare the data and perform data imputation\n",
    "- transform the continuous and categorical data (scaling and encoding respectively)\n",
    "- select the useful features e.g. feature selection, *you can optionally include this in the pipeline or perform this step prior to building the pipeline*\n",
    "- build, train and evaluate the neural network using Keras.\n",
    "- perform hyper-parameter tuning using RandomSearchCV **(optional)**\n",
    "- make predictions with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 – Data Preparation\n",
    "Here is some helpful information on [preprocessing and feature extraction pipelines in scikit-learn](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)\n",
    "\n",
    "<span style=\"color:red\">NOTE: You can modify the cell below to suit your needs. However, ensure that the preprocessing steps that you perform is done in the data frame e.g. `data` </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop fields where more than 92% of all values are the same\n",
    "#for col in data.columns:\n",
    "#    if data[col].isna().sum() > 0:\n",
    "#        if data[col].dtype == 'float64':\n",
    "#            data[col].fillna(0, inplace = True)\n",
    "#        else:\n",
    "#            data[col].fillna('none', inplace = True)\n",
    "#for col in data.columns:\n",
    "#    if (data[col].value_counts()/data[col].value_counts().sum()).iat[0] > .92:\n",
    "#        data.drop(col, axis = 1, inplace = True)\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute missing continuous values with the median and scale the data\n",
    "\n",
    "continuous_features  = [i for i in data.columns if data[i].dtype == 'float64' or data[i].dtype == 'int64'  and i != 'SalePrice'] #TODO: provide a list of continuous fields that will be used in the model(except the dependent variable)\n",
    "continous_transformer = Pipeline(\n",
    "    steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "#impute the NA categorical values and encode the data\n",
    "\n",
    "categorical_features = [i for i in data.columns if data[i].dtype == 'O'] #TODO: provide a list of categorical fields that will be used in the model\n",
    "categorical_transformer = Pipeline(\n",
    "    steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'constant', fill_value = 'NotApp')), #Use an alternative value to indicate NA in the dataset\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ])\n",
    "\n",
    "data_preprocessor   = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('continious', continous_transformer, continuous_features),\n",
    "        ('categorical', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "#NOTE: the steps above will not be performed until we call `fit_transform` (in the next cell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 – Data Transformation & Feature Selection\n",
    "Here is some helpful information on [feature selection as part of a pipeline](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection-as-part-of-a-pipeline). If you add a feature selection algorithm to the pipeline, ensure that it supports regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipeline  = Pipeline(steps=[('preprocessor', data_preprocessor), #This performs the data preparation steps in the cell above\n",
    "                     ('feature_selection', SelectKBest(score_func = f_regression, k = 17) #TODO: identify a feature selection algorithm or exclude this line if you have previously performed feature selection on the data.\n",
    "                                                          ), \n",
    "                    ])\n",
    "\n",
    "transformed_data    = data_prep_pipeline.fit_transform(data.iloc[:, :-1], data['SalePrice']) #transform the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 – Building the Model\n",
    "#### Build the neural network using Keras\n",
    "Build a feed forward neural network with: an input layer, hidden layers and one output layer. \n",
    "\n",
    "Note: you are required to provide a suitable [optimizer](https://keras.io/api/optimizers/) and [loss function](https://keras.io/api/losses/) for the regression task. Optimizers include: 'Adam', 'SGD' and RMSprop. Loss functions include: 'mean_squared_error', 'mean_squared_logarithmic_error', 'mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 39340683264.0000 - mean_absolute_percentage_error: 99.9103 - val_loss: 37934698496.0000 - val_mean_absolute_percentage_error: 99.5395\n",
      "Epoch 2/48\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 37425487872.0000 - mean_absolute_percentage_error: 97.0990 - val_loss: 32711876608.0000 - val_mean_absolute_percentage_error: 91.1632\n",
      "Epoch 3/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 23815704576.0000 - mean_absolute_percentage_error: 73.5544 - val_loss: 9414905856.0000 - val_mean_absolute_percentage_error: 45.1783\n",
      "Epoch 4/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5902906880.0000 - mean_absolute_percentage_error: 37.9661 - val_loss: 6064299008.0000 - val_mean_absolute_percentage_error: 31.8435\n",
      "Epoch 5/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3823553280.0000 - mean_absolute_percentage_error: 28.5616 - val_loss: 4238645760.0000 - val_mean_absolute_percentage_error: 26.9057\n",
      "Epoch 6/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3033061888.0000 - mean_absolute_percentage_error: 25.3544 - val_loss: 3916264960.0000 - val_mean_absolute_percentage_error: 25.1151\n",
      "Epoch 7/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2782929664.0000 - mean_absolute_percentage_error: 23.8345 - val_loss: 3469093888.0000 - val_mean_absolute_percentage_error: 23.6634\n",
      "Epoch 8/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2417058048.0000 - mean_absolute_percentage_error: 22.3738 - val_loss: 3255883520.0000 - val_mean_absolute_percentage_error: 22.4989\n",
      "Epoch 9/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2192876800.0000 - mean_absolute_percentage_error: 21.0727 - val_loss: 3046253056.0000 - val_mean_absolute_percentage_error: 21.6575\n",
      "Epoch 10/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2033208192.0000 - mean_absolute_percentage_error: 20.3628 - val_loss: 2891419648.0000 - val_mean_absolute_percentage_error: 21.0223\n",
      "Epoch 11/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1894370048.0000 - mean_absolute_percentage_error: 19.6575 - val_loss: 2787569920.0000 - val_mean_absolute_percentage_error: 20.4287\n",
      "Epoch 12/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1776329472.0000 - mean_absolute_percentage_error: 19.1013 - val_loss: 2626388480.0000 - val_mean_absolute_percentage_error: 19.7822\n",
      "Epoch 13/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1684791680.0000 - mean_absolute_percentage_error: 18.5007 - val_loss: 2562483456.0000 - val_mean_absolute_percentage_error: 19.3251\n",
      "Epoch 14/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1593241600.0000 - mean_absolute_percentage_error: 17.9190 - val_loss: 2430913792.0000 - val_mean_absolute_percentage_error: 18.6834\n",
      "Epoch 15/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1530991360.0000 - mean_absolute_percentage_error: 17.5439 - val_loss: 2378285824.0000 - val_mean_absolute_percentage_error: 18.1975\n",
      "Epoch 16/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1477106560.0000 - mean_absolute_percentage_error: 16.9998 - val_loss: 2284983808.0000 - val_mean_absolute_percentage_error: 17.7952\n",
      "Epoch 17/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1408760064.0000 - mean_absolute_percentage_error: 16.5074 - val_loss: 2272502528.0000 - val_mean_absolute_percentage_error: 17.5914\n",
      "Epoch 18/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1365904384.0000 - mean_absolute_percentage_error: 16.0995 - val_loss: 2187217408.0000 - val_mean_absolute_percentage_error: 17.0104\n",
      "Epoch 19/48\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1308144256.0000 - mean_absolute_percentage_error: 15.6813 - val_loss: 2184690944.0000 - val_mean_absolute_percentage_error: 16.7826\n",
      "Epoch 20/48\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1266218368.0000 - mean_absolute_percentage_error: 15.3171 - val_loss: 2178788608.0000 - val_mean_absolute_percentage_error: 16.6024\n",
      "Epoch 21/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1250678272.0000 - mean_absolute_percentage_error: 14.9971 - val_loss: 2044083328.0000 - val_mean_absolute_percentage_error: 15.8889\n",
      "Epoch 22/48\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1230369536.0000 - mean_absolute_percentage_error: 14.6756 - val_loss: 2084113152.0000 - val_mean_absolute_percentage_error: 15.9281\n",
      "Epoch 23/48\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1177021824.0000 - mean_absolute_percentage_error: 14.3393 - val_loss: 1961110016.0000 - val_mean_absolute_percentage_error: 15.3063\n",
      "Epoch 24/48\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1126827264.0000 - mean_absolute_percentage_error: 13.9151 - val_loss: 1995500032.0000 - val_mean_absolute_percentage_error: 15.1555\n",
      "Epoch 25/48\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 1119182208.0000 - mean_absolute_percentage_error: 13.6241 - val_loss: 1941101440.0000 - val_mean_absolute_percentage_error: 14.7080\n",
      "Epoch 26/48\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1102842880.0000 - mean_absolute_percentage_error: 13.5404 - val_loss: 1975665664.0000 - val_mean_absolute_percentage_error: 14.9241\n",
      "Epoch 27/48\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1067536128.0000 - mean_absolute_percentage_error: 13.1629 - val_loss: 1941828864.0000 - val_mean_absolute_percentage_error: 14.5922\n",
      "Epoch 28/48\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1069069760.0000 - mean_absolute_percentage_error: 12.9542 - val_loss: 1982413568.0000 - val_mean_absolute_percentage_error: 14.7398\n",
      "Epoch 29/48\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1069977344.0000 - mean_absolute_percentage_error: 12.8436 - val_loss: 1891874560.0000 - val_mean_absolute_percentage_error: 14.1474\n",
      "Epoch 30/48\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1036564544.0000 - mean_absolute_percentage_error: 12.9152 - val_loss: 1863926400.0000 - val_mean_absolute_percentage_error: 13.8321\n",
      "Epoch 31/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1029961216.0000 - mean_absolute_percentage_error: 12.6300 - val_loss: 1918085760.0000 - val_mean_absolute_percentage_error: 13.9959\n",
      "Epoch 32/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1001665472.0000 - mean_absolute_percentage_error: 12.3469 - val_loss: 1841252224.0000 - val_mean_absolute_percentage_error: 13.7960\n",
      "Epoch 33/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 997684608.0000 - mean_absolute_percentage_error: 12.3973 - val_loss: 1934572544.0000 - val_mean_absolute_percentage_error: 14.0249\n",
      "Epoch 34/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 984904768.0000 - mean_absolute_percentage_error: 12.3404 - val_loss: 1832742400.0000 - val_mean_absolute_percentage_error: 13.4446\n",
      "Epoch 35/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1030735616.0000 - mean_absolute_percentage_error: 12.3256 - val_loss: 1915140352.0000 - val_mean_absolute_percentage_error: 13.8506\n",
      "Epoch 36/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1007621120.0000 - mean_absolute_percentage_error: 12.1603 - val_loss: 1897978880.0000 - val_mean_absolute_percentage_error: 13.8668\n",
      "Epoch 37/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 965589760.0000 - mean_absolute_percentage_error: 11.9658 - val_loss: 1835287808.0000 - val_mean_absolute_percentage_error: 13.3305\n",
      "Epoch 38/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 953328064.0000 - mean_absolute_percentage_error: 12.2170 - val_loss: 1875479936.0000 - val_mean_absolute_percentage_error: 13.3658\n",
      "Epoch 39/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 938011072.0000 - mean_absolute_percentage_error: 11.7741 - val_loss: 1845700992.0000 - val_mean_absolute_percentage_error: 13.5822\n",
      "Epoch 40/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 948344256.0000 - mean_absolute_percentage_error: 12.1574 - val_loss: 1826306432.0000 - val_mean_absolute_percentage_error: 13.3359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 954413696.0000 - mean_absolute_percentage_error: 12.1305 - val_loss: 1963329024.0000 - val_mean_absolute_percentage_error: 13.8256\n",
      "Epoch 42/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 956110656.0000 - mean_absolute_percentage_error: 11.8248 - val_loss: 1852399360.0000 - val_mean_absolute_percentage_error: 13.5048\n",
      "Epoch 43/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 958289216.0000 - mean_absolute_percentage_error: 11.8410 - val_loss: 1879990656.0000 - val_mean_absolute_percentage_error: 13.6638\n",
      "Epoch 44/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 940417920.0000 - mean_absolute_percentage_error: 12.0315 - val_loss: 1805649664.0000 - val_mean_absolute_percentage_error: 13.0761\n",
      "Epoch 45/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 944247872.0000 - mean_absolute_percentage_error: 11.9787 - val_loss: 1925107712.0000 - val_mean_absolute_percentage_error: 13.3410\n",
      "Epoch 46/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 940053312.0000 - mean_absolute_percentage_error: 11.6987 - val_loss: 1865590656.0000 - val_mean_absolute_percentage_error: 13.2676\n",
      "Epoch 47/48\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 958846400.0000 - mean_absolute_percentage_error: 11.6727 - val_loss: 1873948672.0000 - val_mean_absolute_percentage_error: 13.0950\n",
      "Epoch 48/48\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 925772416.0000 - mean_absolute_percentage_error: 11.4559 - val_loss: 1955952256.0000 - val_mean_absolute_percentage_error: 13.8337\n"
     ]
    }
   ],
   "source": [
    "X = transformed_data.toarray() #this is the transformed data from the pipeline\n",
    "y = data['SalePrice'] #this is the output\n",
    "\n",
    "#Build a sequential model with at least three dense layers (you can add more layers as needed)\n",
    "#Note: you can also add this keras model to the data preprocessing pipeline but we can skip that step for now.\n",
    "ffnn_model = Sequential()\n",
    "ffnn_model.add(Dense(40, activation='relu', input_shape=(X.shape[1],))) #X.shape[1] is the number of selected features \n",
    "\n",
    "#TODO: Add the first hidden layer with a suitable number of units/neurons and the 'relu' activation function\n",
    "#TODO: Add the second hidden layer with a suitable number of units/neurons and the 'relu' activation function\n",
    "ffnn_model.add(Dense(100, activation = 'relu'))\n",
    "ffnn_model.add(Dense(100, activation = 'relu'))\n",
    "#TODO: Add the output layer\n",
    "ffnn_model.add(Dense(1))\n",
    "ffnn_model.compile(optimizer= keras.optimizers.Adam(learning_rate=0.01), #TODO: state the optimize\n",
    "                   loss= keras.losses.MeanSquaredError(),      #TODO: state the loss function\n",
    "                   metrics= [keras.metrics.MeanAbsolutePercentageError()]     #TODO: state the metric\n",
    "                  )\n",
    "\n",
    "ffnn_history = ffnn_model.fit(X, y, \n",
    "                              validation_split= 0.3, #TODO: state the validation split\n",
    "                              epochs= 48, #TODO: state the number of epochs (you may need to run the model a few times to find a suitable value)\n",
    "                              batch_size=64 , #TODO: state the number of observations to use in each batch\n",
    "                              verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training and validation loss\n",
    "plt.plot(ffnn_history.history['loss'], 'b', ffnn_history.history['val_loss'], 'orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the neural network to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Load the data from `house_prices_test.csv`\n",
    "test_data_url = 'https://raw.githubusercontent.com/clarkech95/fwd-feed-neural-netwrk/master/house_prices_test.csv'\n",
    "test_data = pd.read_csv(test_data_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the test data using the pipeline\n",
    "This will impute any missing values and scale/encode the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clark\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "prep_test_data = data_prep_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the neural network to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ffnn_model.predict( #TODO: provide the preprocessed test data (above)\n",
    "        prep_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Display samples of the predictions from your model and summarize your thoughts on the model's performance, the training process and its ability to generalize with new data. What are your recommendations to improve the model in the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115027.11]\n",
      " [ 84085.95]\n",
      " [199257.75]\n",
      " [172810.92]\n",
      " [181332.94]\n",
      " [206765.84]\n",
      " [246815.9 ]\n",
      " [203583.22]\n",
      " [168945.58]\n",
      " [115747.22]]\n"
     ]
    }
   ],
   "source": [
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0\n",
      "count    1459.000000\n",
      "mean   171945.765625\n",
      "std     84327.656250\n",
      "min     41396.203125\n",
      "25%    115869.054688\n",
      "50%    144842.218750\n",
      "75%    204720.289062\n",
      "max    924075.062500\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(result).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the model performed fairly well and did a good job of generalizing new data. After a certain point the ability to improve the model tapers off and there is little increase to performance with each additional iteration. I think the best thing for imrpoving this dataset would be to add more training data to it. This would allow our already optimized model to better interpret patterns for new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
